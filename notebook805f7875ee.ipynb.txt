{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Let's add the libraries where they are really needed, not all of them at the first line","metadata":{}},{"cell_type":"code","source":"address = '../input/face-detection-in-images/face_detection.json'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport codecs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get links and stuff from json\n\njsonData = []\n\nwith codecs.open(address, 'rU', 'utf-8') as js:\n    for line in js:\n        jsonData.append(json.loads(line))\n\nprint(f\"{len(jsonData)} image found!\")\n\nprint(\"Sample row:\")\n\njsonData[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport requests\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom io import BytesIO","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load images from url and save into images\n\nimages = []\n\nfor data in tqdm(jsonData):\n    response = requests.get(data['content'])\n    img = np.asarray(Image.open(BytesIO(response.content)))\n    images.append([img, data[\"annotation\"]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir face-detection-images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 1\n\ntotalfaces = 0\n\nstart = time.time()\n\nfor image in images:\n    img = image[0]\n    metadata = image[1]\n    for data in metadata:\n        height = data['imageHeight']\n        width = data['imageWidth']\n        points = data['points']\n        if 'Face' in data['label']:\n            x1 = round(width*points[0]['x'])\n            y1 = round(height*points[0]['y'])\n            x2 = round(width*points[1]['x'])\n            y2 = round(height*points[1]['y'])\n            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 1)\n            totalfaces += 1\n    cv2.imwrite('./face-detection-images/face_image_{}.jpg'.format(count),img)\n    count += 1\n    \nend = time.time()\n\nprint(\"Total test images with faces : {}\".format(len(images)))\nprint(\"Sucessfully tested {} images\".format(count-1))\nprint(\"Execution time in seconds {}\".format(end-start))\nprint(\"Total Faces Detected {}\".format(totalfaces))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"face1 = cv2.imread(\"./face-detection-images/face_image_64.jpg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,25))\nplt.imshow(face1)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18,15))\nplt.imshow(cv2.cvtColor(face1, cv2.COLOR_BGR2RGB))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"face2 = cv2.imread(\"./face-detection-images/face_image_400.jpg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,25))\nplt.imshow(face2)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}